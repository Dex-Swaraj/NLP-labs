"""
MASTER SCRIPT - Run All 4 Advanced NLP Practicals
This script executes all practicals in sequence with progress tracking
"""

import subprocess
import sys
import time
from datetime import datetime

def print_banner(text):
    """Print a styled banner"""
    print("\n" + "="*80)
    print(f"  {text}")
    print("="*80 + "\n")

def run_practical(script_name, practical_num, description):
    """Run a single practical script"""
    print_banner(f"PRACTICAL {practical_num}: {description}")
    
    print(f"‚è±Ô∏è  Starting: {datetime.now().strftime('%H:%M:%S')}")
    start_time = time.time()
    
    try:
        # Run the script
        result = subprocess.run(
            [sys.executable, script_name],
            capture_output=False,
            text=True,
            check=True
        )
        
        elapsed = time.time() - start_time
        print(f"\n‚úÖ Completed in {elapsed:.2f} seconds")
        return True, elapsed
        
    except subprocess.CalledProcessError as e:
        print(f"\n‚ùå Error running {script_name}")
        print(f"Error: {e}")
        return False, 0
    except Exception as e:
        print(f"\n‚ùå Unexpected error: {e}")
        return False, 0

def main():
    print("\n" + "üöÄ"*40)
    print("   ADVANCED NLP PRACTICALS - MASTER EXECUTION SUITE")
    print("   Running all 4 practicals sequentially...")
    print("üöÄ"*40)
    
    # Define practicals
    practicals = [
        {
            'script': 'practical1_tokenization_stemming.py',
            'num': 1,
            'desc': 'Advanced Tokenization & Stemming Analysis'
        },
        {
            'script': 'practical2_bow_tfidf_word2vec.py',
            'num': 2,
            'desc': 'BOW, TF-IDF & Word2Vec with Clustering'
        },
        {
            'script': 'practical3_preprocessing_tfidf.py',
            'num': 3,
            'desc': 'Text Preprocessing & Feature Engineering'
        },
        {
            'script': 'practical4_ner_advanced.py',
            'num': 4,
            'desc': 'Named Entity Recognition System'
        }
    ]
    
    # Track results
    results = []
    total_start = time.time()
    
    # Run each practical
    for practical in practicals:
        success, elapsed = run_practical(
            practical['script'],
            practical['num'],
            practical['desc']
        )
        results.append({
            'num': practical['num'],
            'name': practical['desc'],
            'success': success,
            'time': elapsed
        })
        
        if not success:
            print(f"\n‚ö†Ô∏è  Practical {practical['num']} failed. Continuing...")
        
        # Small delay between practicals
        time.sleep(1)
    
    # Final summary
    total_time = time.time() - total_start
    
    print("\n" + "="*80)
    print("  üìä EXECUTION SUMMARY")
    print("="*80)
    
    successful = sum(1 for r in results if r['success'])
    failed = len(results) - successful
    
    print(f"\n‚úÖ Successful: {successful}/{len(results)}")
    print(f"‚ùå Failed: {failed}/{len(results)}")
    print(f"‚è±Ô∏è  Total time: {total_time:.2f} seconds ({total_time/60:.2f} minutes)")
    
    print("\nüìã Individual Results:")
    print("-" * 80)
    for r in results:
        status = "‚úÖ PASS" if r['success'] else "‚ùå FAIL"
        print(f"  Practical {r['num']}: {status:10s} - {r['time']:6.2f}s - {r['name']}")
    
    print("\n" + "="*80)
    if successful == len(results):
        print("  üéâ ALL PRACTICALS COMPLETED SUCCESSFULLY!")
    else:
        print(f"  ‚ö†Ô∏è  {failed} practical(s) had errors. Check logs above.")
    print("="*80)
    
    # List output files
    print("\nüìÅ Generated Output Files:")
    print("-" * 80)
    print("""
Practical 1:
  ‚Ä¢ tokenization_comparison.png
  ‚Ä¢ stemming_analysis.png
  ‚Ä¢ stemmer_comparison.csv
  ‚Ä¢ stemmer_differences.csv

Practical 2:
  ‚Ä¢ bow_counts.csv, bow_normalized.csv
  ‚Ä¢ tfidf_scores.csv, idf_values.csv
  ‚Ä¢ word2vec_cbow.model, word2vec_skipgram.model
  ‚Ä¢ document_vectors.npy
  ‚Ä¢ word2vec_3d.png
  ‚Ä¢ word_clusters.png
  ‚Ä¢ similarity_bow.png, similarity_tfidf.png, similarity_word2vec.png
  ‚Ä¢ comparative_analysis.png

Practical 3:
  ‚Ä¢ preprocessed_texts.csv
  ‚Ä¢ augmented_texts.csv
  ‚Ä¢ tfidf_features.csv
  ‚Ä¢ label_encoding.csv
  ‚Ä¢ quality_metrics.csv
  ‚Ä¢ preprocessing_impact.png
  ‚Ä¢ feature_importance.png

Practical 4:
  ‚Ä¢ extracted_entities.csv
  ‚Ä¢ ner_predictions.csv
  ‚Ä¢ ner_metrics.csv
  ‚Ä¢ classification_report.csv
  ‚Ä¢ entity_distribution.png
  ‚Ä¢ confusion_matrix.png
  ‚Ä¢ performance_metrics.png

Total: 30+ output files!
    """)
    
    print("="*80)
    print("  üåü Check the README.md for detailed documentation")
    print("="*80 + "\n")

if __name__ == "__main__":
    main()
